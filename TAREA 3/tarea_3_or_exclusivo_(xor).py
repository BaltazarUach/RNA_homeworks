# -*- coding: utf-8 -*-
"""Tarea 3 or-exclusivo (XOR).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y3FNy7r3pU1xpqUPJtriS-y-bTD6o-yd
"""

# TAREA 3. or-exclusivo (XOR)      01-04-2025
# POSGRADO EN INGENIERÍA AGRÍCOLA Y USO INTEGRAL DEL AGUA
# BALTAZAR LÓPEZ VELASCO
# Los pares de entrada/objetivo para la puerta XOR son:
# {p1 = [0; 0], t1 = 0}
# {p1 = [0; 1], t1 = 1}
# {p1 = [1; 0], t1 = 1}
# {p1 = [1; 1], t1 = 0}

import numpy as np
from keras.models import Sequential
from keras.layers import Dense

# Datos de entrada
training_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])

# Datos de salida
target_data = np.array([[0], [1], [1], [0]])

print(training_data)

print(target_data)

# Para resolver el problema de la or-exclusivo (XOR) se propone usar dos neuronas en la primera capa para crear dos limites de decisión
# Usando Keras para declarar la NN (Neural Network)
model = Sequential()
model.add(Dense(2, input_dim=2, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.summary()

# HYPERPARÁMETROS
model.compile(loss='mean_squared_error', optimizer='adam', metrics=['binary_accuracy'])

# ENTRENAMOS
model.fit(training_data, target_data, epochs=2500, verbose=2)

# EVALUAMOS
scores = model.evaluate(training_data, target_data)
print("\n%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
print(model.predict(training_data).round())

# PESOS Y SESGO

print("\nPesos y sesgos del modelo:")
for i, layer in enumerate(model.layers):
    weights, biases = layer.get_weights()
    print(f"\nCapa {i + 1} - Pesos:\n{weights}")
    print(f"Capa {i + 1} - Sesgos:\n{biases}")

